import tiktoken

# Load tokenizer for GPT-3.5
tokenizer = tiktoken.encoding_for_model("gpt-3.5-turbo")

text = "Artificial Intelligence is transforming every industry from healthcare to finance."

# Tokenize and count
tokens = tokenizer.encode(text)
print(f"Token count: {len(tokens)}")
print("Tokens:", tokens)
